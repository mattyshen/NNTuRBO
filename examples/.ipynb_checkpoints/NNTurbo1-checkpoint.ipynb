{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple example of TuRBO-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mattyshen/NNTuRBO\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnturbo import NNTurbo1\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up an optimization problem class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Levy:\n",
    "    def __init__(self, dim=10):\n",
    "        self.dim = dim\n",
    "        self.lb = -5 * np.ones(dim)\n",
    "        self.ub = 10 * np.ones(dim)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        assert len(x) == self.dim\n",
    "        assert x.ndim == 1\n",
    "        assert np.all(x <= self.ub) and np.all(x >= self.lb)\n",
    "        w = 1 + (x - 1.0) / 4.0\n",
    "        val = np.sin(np.pi * w[0]) ** 2 + \\\n",
    "            np.sum((w[1:self.dim - 1] - 1) ** 2 * (1 + 10 * np.sin(np.pi * w[1:self.dim - 1] + 1) ** 2)) + \\\n",
    "            (w[self.dim - 1] - 1) ** 2 * (1 + np.sin(2 * np.pi * w[self.dim - 1])**2)\n",
    "        return val\n",
    "\n",
    "f = Levy(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Turbo optimizer instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dtype = torch.float64 \n",
      "Using device = cpu\n"
     ]
    }
   ],
   "source": [
    "turbo1 = NNTurbo1(\n",
    "    f=f,  # Handle to objective function\n",
    "    lb=f.lb,  # Numpy array specifying lower bounds\n",
    "    ub=f.ub,  # Numpy array specifying upper bounds\n",
    "    n_init=20,  # Number of initial bounds from an Latin hypercube design\n",
    "    max_evals = 1000,  # Maximum number of evaluations\n",
    "    batch_size=10,  # How large batch size TuRBO uses\n",
    "    verbose=True,  # Print information from each batch\n",
    "    use_ard=True,  # Set to true if you want to use ARD for the GP kernel\n",
    "    max_cholesky_size=2000,  # When we switch from Cholesky to Lanczos\n",
    "    n_training_steps=50,  # Number of steps of ADAM to learn the hypers\n",
    "    min_cuda=1024,  # Run on the CPU for small datasets\n",
    "    device=\"cuda\",  # \"cpu\" or \"cuda\"\n",
    "    dtype=\"float64\",  # float64 or float32\n",
    "    prop=1.2,\n",
    "    p=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the optimization process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from fbest = 12.81\n",
      "k: 1000\n",
      "(1200, 10) (1000, 10)\n",
      "(1000, 10) (1000, 10)\n",
      "k: 833\n",
      "(1200, 10) (833, 10)\n",
      "(833, 10) (833, 10)\n",
      "40) New best: 9.919\n",
      "k: 833\n",
      "(1200, 10) (833, 10)\n",
      "(833, 10) (833, 10)\n",
      "k: 694\n",
      "(1200, 10) (694, 10)\n",
      "(694, 10) (694, 10)\n",
      "60) New best: 6.093\n",
      "k: 694\n",
      "(1200, 10) (694, 10)\n",
      "(694, 10) (694, 10)\n",
      "70) New best: 3.956\n",
      "k: 694\n",
      "(1200, 10) (694, 10)\n",
      "(694, 10) (694, 10)\n",
      "k: 578\n",
      "(1200, 10) (578, 10)\n",
      "(578, 10) (578, 10)\n",
      "k: 481\n",
      "(1200, 10) (481, 10)\n",
      "(481, 10) (481, 10)\n",
      "k: 400\n",
      "(1200, 10) (400, 10)\n",
      "(400, 10) (400, 10)\n",
      "k: 333\n",
      "(1200, 10) (333, 10)\n",
      "(333, 10) (333, 10)\n",
      "k: 277\n",
      "(1200, 10) (277, 10)\n",
      "(277, 10) (277, 10)\n",
      "k: 230\n",
      "(1200, 10) (230, 10)\n",
      "(230, 10) (230, 10)\n",
      "k: 191\n",
      "(1200, 10) (191, 10)\n",
      "(191, 10) (191, 10)\n",
      "150) New best: 3.629\n",
      "k: 191\n",
      "(1200, 10) (191, 10)\n",
      "(191, 10) (191, 10)\n",
      "160) New best: 3.082\n",
      "k: 191\n",
      "(1200, 10) (191, 10)\n",
      "(191, 10) (191, 10)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mturbo1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/NNTuRBO/nnturbo/nn_turbo_1.py:301\u001b[0m, in \u001b[0;36mNNTurbo1.optimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    299\u001b[0m fX \u001b[38;5;241m=\u001b[39m deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fX)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# Create th next batch\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m X_cand, y_cand, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_training_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_training_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_cand\u001b[38;5;241m.\u001b[39mshape, y_cand\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    305\u001b[0m X_next \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_candidates(X_cand, y_cand)\n",
      "File \u001b[0;32m~/NNTuRBO/nnturbo/nn_turbo_1.py:191\u001b[0m, in \u001b[0;36mNNTurbo1._create_candidates\u001b[0;34m(self, X, fX, length, k, n_training_steps, hypers)\u001b[0m\n\u001b[1;32m    189\u001b[0m X_torch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X)\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    190\u001b[0m y_torch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(fX)\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m--> 191\u001b[0m gp \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_gp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_torch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_torch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_ard\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_ard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_training_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhypers\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# Save state dict\u001b[39;00m\n\u001b[1;32m    196\u001b[0m hypers \u001b[38;5;241m=\u001b[39m gp\u001b[38;5;241m.\u001b[39mstate_dict()\n",
      "File \u001b[0;32m~/NNTuRBO/nnturbo/gp.py:91\u001b[0m, in \u001b[0;36mtrain_gp\u001b[0;34m(train_x, train_y, use_ard, num_steps, hypers)\u001b[0m\n\u001b[1;32m     89\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(train_x)\n\u001b[1;32m     90\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mmll(output, train_y)\n\u001b[0;32m---> 91\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Switch to eval mode\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "turbo1.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract all evaluations from Turbo and print the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = turbo1.X  # Evaluated points\n",
    "fX = turbo1.fX  # Observed values\n",
    "ind_best = np.argmin(fX)\n",
    "f_best, x_best = fX[ind_best], X[ind_best, :]\n",
    "\n",
    "print(\"Best value found:\\n\\tf(x) = %.3f\\nObserved at:\\n\\tx = %s\" % (f_best, np.around(x_best, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the progress\n",
    "Each trust region is independent and finds different solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 5))\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "plt.plot(fX, 'b.', ms=10)  # Plot all evaluated points as blue dots\n",
    "plt.plot(np.minimum.accumulate(fX), 'r', lw=3)  # Plot cumulative minimum as a red line\n",
    "plt.xlim([0, len(fX)])\n",
    "plt.ylim([0, 30])\n",
    "plt.title(\"10D Levy function\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
